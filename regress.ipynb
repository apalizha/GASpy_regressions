{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# regress.ipynb\n",
    "Author:  Kevin Tran <ktran@andrew.cmu.edu>\n",
    "\n",
    "This python notebook performs regressions on data pulled from a local GASdb. It then saves these regressions into pickles (for later use) and creates parity plots of the regression fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint   # for debugging\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from gaspy.utils import vasp_settings_to_str\n",
    "from gas_pull import GASPull\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from tpot import TPOTRegressor\n",
    "import alamopy\n",
    "import dill as pickle\n",
    "pickle.settings['recurse'] = True     # required to pickle lambdify functions\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Location of the *.db file\n",
    "#DB_LOC = '/global/cscratch1/sd/zulissi/GASpy_DB/'  # Cori\n",
    "DB_LOC = '/Users/KTran/Nerd/GASpy'                 # Local\n",
    "\n",
    "# Calculation settings we want to look at\n",
    "VASP_SETTINGS = utils.vasp_settings_to_str({'gga': 'BF',\n",
    "                                            'pp_version': '5.4.',\n",
    "                                            'encut': 350})\n",
    "\n",
    "# Pull the data from the Local database\n",
    "GAS_PULL = GASPull(DB_LOC, VASP_SETTINGS, split=True)\n",
    "X, Y, DATA, X_TRAIN, X_TEST, Y_TRAIN, Y_TEST, lb_ads, lb_coord = \\\n",
    "        GAS_PULL.energy_fr_coordcount_neighborcount_ads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regressions\n",
    "Create surrogate models using different methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### SKLearn Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X_TRAIN, Y_TRAIN)\n",
    "LR.name = 'Linear'\n",
    "pickle.dump({'model': LR,\n",
    "             'pre_processors': {'coordination': lb_coord,\n",
    "                                'adsorbate': lb_ads}},\n",
    "            open('pkls/CoordcountNeighborcountAds_Energy_LR.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### SKLearn Gradient Boosting Ensemble Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "GBE = GradientBoostingRegressor()\n",
    "GBE.fit(X_TRAIN, Y_TRAIN)\n",
    "GBE.name = 'GBE'\n",
    "pickle.dump({'model': GBE,\n",
    "             'pre_processors': {'coordination': lb_coord,\n",
    "                                'adsorbate': lb_ads}},\n",
    "            open('pkls/CoordcountNeighborcountAds_Energy_GBE.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### SKLearn Gaussian Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "GP = GaussianProcessRegressor()\n",
    "GP.fit(X_TRAIN, Y_TRAIN)\n",
    "GP.name = 'GP'\n",
    "pickle.dump({'model': GP,\n",
    "             'pre_processors': {'coordination': lb_coord,\n",
    "                                'adsorbate': lb_ads}},\n",
    "            open('pkls/CoordcountNeighborcountAds_Energy_GP.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### TPOT Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "TPOT = TPOTRegressor(generations=100,\n",
    "                     population_size=100,\n",
    "                     verbosity=2,\n",
    "                     random_state=42)\n",
    "TPOT.fit(X_TRAIN, Y_TRAIN)\n",
    "TPOT.name = 'TPOT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump({'model': TPOT.fitted_pipeline_,\n",
    "             'pre_processors': {'coordination': lb_coord,\n",
    "                                'adsorbate': lb_ads}},\n",
    "            open('pkls/CoordcountNeighborcountAds_Energy_TPOT.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TPOT_PKL = pickle.load(open('pkls/CoordcountNeighborcountAds_Energy_TPOT.pkl', 'r'))\n",
    "TPOT = TPOT_PKL['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Alamo Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Since Alamo can take awhile, we actually try to load a pickle of the previous run\n",
    "# before calling alamopy. Simply delete the pickle if you want to re-run.\n",
    "try:\n",
    "    ALA = pickle.load(open('pkls/CoordcountNeighborcountAds_Energy_Ala.pkl', 'r'))['model']\n",
    "except IOError:\n",
    "    ALA = alamopy.doalamo(X_TRAIN, Y_TRAIN.reshape(len(Y_TRAIN), 1),\n",
    "                          X_TEST, Y_TEST.reshape(len(Y_TEST), 1),\n",
    "                          showalm=1,\n",
    "                          linfcns=1,\n",
    "                          expfcns=1,\n",
    "                          logfcns=1,\n",
    "                          monomialpower=(1, 2, 3),\n",
    "                          multi2power=(1, 2, 3),\n",
    "                          ratiopower=(1, 2, 3)\n",
    "                         )\n",
    "    ALA['name'] = 'Alamo'\n",
    "    pickle.dump({'model': ALA,\n",
    "                 'pre_processors': {'coordination': lb_coord,\n",
    "                                    'adsorbate': lb_ads}},\n",
    "                open('pkls/CoordcountNeighborcountAds_Energy_Ala.pkl', 'w'))\n",
    "pprint(ALA['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### SKLearn-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model...\n",
    "for model in [LR, GBE, GP, TPOT]:\n",
    "    traces = []\n",
    "    # Create a parity plot where each adsorbate is shown. We do that by pulling out\n",
    "    # data for each adsorbate and then plotting them.\n",
    "    for ads in np.unique(DATA['adsorbate']):\n",
    "        # We loop through all of our data and pull out the vectorized coordinations (x),\n",
    "        # the DFT energy (y), and the coordination site (text).\n",
    "        x = []\n",
    "        y = []\n",
    "        text = []\n",
    "        for i, _ads in enumerate(DATA['adsorbate']):\n",
    "            if _ads == ads:\n",
    "                x.append(X[i])\n",
    "                y.append(Y[i])\n",
    "                text.append('Site:  %s\\rNeighbor:  %s' \\\n",
    "                            % (DATA['coordination'][i],\n",
    "                               DATA['nextnearestcoordination'][i]))\n",
    "        # Use the vectorized coordination (x) to calculate a predicted energy (y_predicted).\n",
    "        # Then add it to `traces` for plotting.\n",
    "        y_predicted = model.predict(np.array(x))\n",
    "        traces.append(go.Scatter(x=y_predicted,\n",
    "                                 y=y,\n",
    "                                 mode='markers',\n",
    "                                 text=text,\n",
    "                                 name=ads))\n",
    "    # Create a diagonal line for the parity plot\n",
    "    lims = [-4, 6]\n",
    "    traces.append(go.Scatter(x=lims, y=lims,\n",
    "                             line=dict(color=('black'), dash='dash'), name='Parity line'))\n",
    "    # Format and plot\n",
    "    layout = go.Layout(xaxis=dict(title='Regressed (eV)'),\n",
    "                       yaxis=dict(title='DFT (eV)'),\n",
    "                       title='Adsorption Energy as a function of (Coordination Count, Neighbor Coordination Count, Adsorbate); Model = %s; RMSE = %0.3f eV' \\\n",
    "                             % (model.name, math.sqrt(metrics.mean_squared_error(Y_TEST, model.predict(X_TEST)))))\n",
    "    iplot(go.Figure(data=traces, layout=layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Alamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Create Pyplot plots for each dictionary-type model\n",
    "for model in [ALA]:\n",
    "    traces = []\n",
    "    # Create a parity plot where each adsorbate is shown. We do that by pulling out\n",
    "    # data for each adsorbate and then plotting them.\n",
    "    for ads in np.unique(DATA['adsorbate']):\n",
    "        # We loop through all of our data and pull out the vectorized coordination (x),\n",
    "        # the DFT energy (y), and the coordination site (text).\n",
    "        x = []\n",
    "        y = []\n",
    "        text = []\n",
    "        for i, _ads in enumerate(DATA['adsorbate']):\n",
    "            if _ads == ads:\n",
    "                x.append(X[i])\n",
    "                y.append(Y[i])\n",
    "                text.append('Site:  %s\\rNeighbor:  %s' \\\n",
    "                            % (DATA['coordination'][i],\n",
    "                               DATA['nextnearestcoordination'][i]))\n",
    "                \n",
    "        # Do some footwork because Alamo returns a lambda function that doesn't accept np arrays\n",
    "        def model_predict(factors):\n",
    "            '''\n",
    "            Turn a vector of input data, `factors`, into the model's guessed output. We use\n",
    "            this function to do so because lambda functions suck. We should address this by\n",
    "            making alamopy output a better lambda function.\n",
    "            '''\n",
    "            args = dict.fromkeys(range(0, len(factors)-1), None)\n",
    "            for j, factor in enumerate(factors):\n",
    "                args[j] = factor\n",
    "            return model['f(model)'](args[0], args[1], args[2], args[3], args[4], args[5], args[6], args[7], args[8], args[9], args[10], args[11], args[12], args[13], args[14], args[15], args[16], args[17], args[18], args[19], args[20], args[21], args[22], args[23], args[24], args[25])\n",
    "        y_predicted = map(model_predict, x)\n",
    "        \n",
    "        # Plot\n",
    "        traces.append(go.Scatter(x=y_predicted,\n",
    "                                 y=y,\n",
    "                                 mode='markers',\n",
    "                                 text=text,\n",
    "                                 name=ads))\n",
    "    # Create a diagonal line for the parity plot\n",
    "    lims = [-4, 6]\n",
    "    traces.append(go.Scatter(x=lims, y=lims,\n",
    "                             line=dict(color=('black'), dash='dash'), name='Parity line'))\n",
    "    # Format and plot\n",
    "    layout = go.Layout(xaxis=dict(title='Regressed (eV)'),\n",
    "                       yaxis=dict(title='DFT (eV)'),\n",
    "                       title='Adsorption Energy as a function of (Coordination Count, Neighbor Coordination Count, Adsorbate); Model = %s; RMSE = %0.3f eV' \\\n",
    "                             % (model['name'], math.sqrt(metrics.mean_squared_error(Y_TEST, map(model_predict, X_TEST)))))\n",
    "    iplot(go.Figure(data=traces, layout=layout))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "regress.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
