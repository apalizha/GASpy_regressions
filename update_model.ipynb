{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# regress.ipynb\n",
    "Author:  Kevin Tran <ktran@andrew.cmu.edu>\n",
    "\n",
    "This python notebook performs regressions on data pulled from a processed mongo DB created by GASpy. It then saves these regressions into pickles (for later use) and creates parity plots of the regression fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Debugging & other Python tools\n",
    "import pdb\n",
    "import sys\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "# Saving/loading\n",
    "import dill as pickle\n",
    "pickle.settings['recurse'] = True     # required to pickle lambdify functions (for alamopy)\n",
    "# Regression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, RationalQuadratic, ExpSineSquared\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "# GASpy\n",
    "from regression_processor import RegressionProcessor\n",
    "from pull_features import PullFeatures\n",
    "sys.path.append('..')\n",
    "from gaspy.utils import vasp_settings_to_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Define the feature sets that you want to investigate. They should be\n",
    "# string names of the PullFeatures methods that you want to use.\n",
    "FEATURE_SETS = [\n",
    "                #'energy_fr_coordcount',\n",
    "                #'energy_fr_coordcount_nncoord',\n",
    "                'energy_fr_coordcount_ads',\n",
    "                #'energy_fr_coordcount_nncoord_ads',\n",
    "                #'energy_fr_nncoord',\n",
    "                #'energy_fr_gcn_ads',\n",
    "               ]\n",
    "\n",
    "# Only pull data that used the following vasp settings\n",
    "VASP_SETTINGS = vasp_settings_to_str({'gga': 'RP',\n",
    "                                      'pp_version': '5.4',\n",
    "                                      'encut': 350})\n",
    "#VASP_SETTINGS = None\n",
    "\n",
    "# This is a dictionary that will hold all of the data we need for plotting\n",
    "DATA = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Regress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hierarchical\n",
    "TODO:  Test the iterable nature of these cells (i.e., use more than one outer and inner combo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/k/ktran/.conda/envs/GASpy_conda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n",
      "/global/homes/k/ktran/.conda/envs/GASpy_conda/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning:\n",
      "\n",
      "Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "\n",
      "Optimization Progress:  38%|███▊      | 30/80 [01:14<02:05,  2.51s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.327593765598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  56%|█████▋    | 45/80 [01:37<00:48,  1.40s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.327593765598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  76%|███████▋  | 61/80 [02:05<00:28,  1.51s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.323181082566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.316648899314\n",
      "\n",
      "Best pipeline: RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.2, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=16, RandomForestRegressor__n_estimators=DEFAULT)\n"
     ]
    }
   ],
   "source": [
    "# Specify the model blocking. Use [] if you don't want blocking (this will help with saving)\n",
    "#blocks = ['adsorbate']\n",
    "blocks = []\n",
    "\n",
    "# Outer regression information\n",
    "OUTER_FEATURE_SETS = ['energy_fr_coordcount_ads']\n",
    "OUTER_REGRESSORS = [TPOTRegressor(generations=4,\n",
    "                                  population_size=16,\n",
    "                                  verbosity=2,\n",
    "                                  random_state=42)]\n",
    "OUTER_REGRESSION_METHODS = ['tpot']\n",
    "OUTER_SYSTEMS = [(outer_feature_set, OUTER_REGRESSORS[i], OUTER_REGRESSION_METHODS[i])\n",
    "                 for i, outer_feature_set in enumerate(OUTER_FEATURE_SETS)]\n",
    "# Inner regression information\n",
    "INNER_FEATURE_SETS = ['energy_fr_nncoord']\n",
    "#K = 1.0*RBF(length_scale=1.0) + 1.0*WhiteKernel(noise_level=0.05**2.0) \n",
    "K = None\n",
    "INNER_REGRESSORS = [GaussianProcessRegressor(kernel=K, n_restarts_optimizer=2)]\n",
    "INNER_REGRESSION_METHODS = ['sk_regressor']\n",
    "INNER_SYSTEMS = [(inner_feature_set, INNER_REGRESSORS[i], INNER_REGRESSION_METHODS[i])\n",
    "                 for i, inner_feature_set in enumerate(INNER_FEATURE_SETS)]\n",
    "\n",
    "# `FEATURE_COMBINATIONS` is a list of tuples for the different combinations\n",
    "# of the outer and inner regressors we want. We use it to initialize the dictionaries\n",
    "# of our results.\n",
    "FEATURE_COMBINATIONS = [combo\n",
    "                        for combo in itertools.product(*[OUTER_FEATURE_SETS,\n",
    "                                                         INNER_FEATURE_SETS])]\n",
    "models = dict.fromkeys(FEATURE_COMBINATIONS)\n",
    "rmses = dict.fromkeys(FEATURE_COMBINATIONS)\n",
    "errors = dict.fromkeys(FEATURE_COMBINATIONS)\n",
    "x = dict.fromkeys(FEATURE_COMBINATIONS)\n",
    "y = dict.fromkeys(FEATURE_COMBINATIONS)\n",
    "p_docs = dict.fromkeys(FEATURE_COMBINATIONS)\n",
    "pp = dict.fromkeys(FEATURE_COMBINATIONS)\n",
    "block_list = dict.fromkeys(FEATURE_COMBINATIONS)\n",
    "# Initialize other output dictionaries\n",
    "RPs = dict.fromkeys(OUTER_FEATURE_SETS)\n",
    "norm = dict.fromkeys(OUTER_FEATURE_SETS+FEATURE_COMBINATIONS)\n",
    "\n",
    "# Perform the regressions for each combination of feature sets\n",
    "for o_feature_set, o_regressor, o_regression_method in OUTER_SYSTEMS:\n",
    "    # Initialize `RegressionProcessor` to pull the data\n",
    "    RPs[o_feature_set] = RegressionProcessor(o_feature_set,\n",
    "                                             blocks=blocks,\n",
    "                                             vasp_settings=VASP_SETTINGS)\n",
    "    # Perform the outer regressions\n",
    "    outer_models, outer_rmses, outer_errors = \\\n",
    "            getattr(RPs[o_feature_set], o_regression_method)(o_regressor)\n",
    "    # Perform the inner regressions\n",
    "    for i_feature_set, i_regressor, i_regression_method in INNER_SYSTEMS:\n",
    "        models[(o_feature_set, i_feature_set)], \\\n",
    "            rmses[(o_feature_set, i_feature_set)], \\\n",
    "            errors[(o_feature_set, i_feature_set)], \\\n",
    "            _, inner_norm \\\n",
    "                = RPs[o_feature_set].hierarchical(outer_models, outer_rmses, outer_errors,\n",
    "                                                  i_feature_set,\n",
    "                                                  i_regression_method,\n",
    "                                                  i_regressor)\n",
    "        # Store some of the RegressionProcessor attributes for later use\n",
    "        x[(o_feature_set, i_feature_set)] = RPs[o_feature_set].x\n",
    "        y[(o_feature_set, i_feature_set)] = RPs[o_feature_set].y\n",
    "        p_docs[(o_feature_set, i_feature_set)] = RPs[o_feature_set].p_docs\n",
    "        pp[(o_feature_set, i_feature_set)] = RPs[o_feature_set].pp\n",
    "        block_list[(o_feature_set, i_feature_set)] = RPs[o_feature_set].block_list\n",
    "        norm[(o_feature_set, i_feature_set)] = inner_norm\n",
    "    norm[o_feature_set] = RPs[o_feature_set].norm\n",
    "        \n",
    "# Package the data that'll be used for plotting\n",
    "DATA['GPinTPOT'] = {'models': models,\n",
    "                    'rmses': rmses,\n",
    "                    'errors': errors,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'p_docs': p_docs,\n",
    "                    'blocks': blocks,\n",
    "                    'block_list': block_list,\n",
    "                    'pp': pp,\n",
    "                    'norm': norm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the regressions\n",
    "for o_feature_set in OUTER_FEATURE_SETS:\n",
    "    for i_feature_set in INNER_FEATURE_SETS:\n",
    "        # Save the models alone for GASpy_predict to use\n",
    "        with open('pkls/models/GPinTPOT_model_' \\\n",
    "                  + i_feature_set + '-inside-' + o_feature_set + '_' \\\n",
    "                  + '-'.join(DATA['GPinTPOT']['blocks']) + '.pkl', 'wb') as f:\n",
    "            pkl = {'model': DATA['GPinTPOT']['models'][(o_feature_set, i_feature_set)],\n",
    "                   'pp': DATA['GPinTPOT']['pp'][(o_feature_set, i_feature_set)],\n",
    "                   'norm': {'outer': DATA['GPinTPOT']['norm'][o_feature_set],\n",
    "                            'inner': DATA['GPinTPOT']['norm'][(o_feature_set, i_feature_set)]}}\n",
    "            pickle.dump(pkl, f)\n",
    "\n",
    "        # Save the entire package to use later in this notebook\n",
    "        data = {}\n",
    "        for datum in ['models', 'rmses', 'errors', 'x', 'y', 'p_docs', 'block_list', 'pp']:\n",
    "            data[datum] = DATA['GPinTPOT'][datum][(o_feature_set, i_feature_set)]\n",
    "        with open('pkls/data/GPinTPOT_data_' \\\n",
    "                  + i_feature_set + '-inside-' + o_feature_set + '_' \\\n",
    "                  + '-'.join(DATA['GPinTPOT']['blocks']) + '.pkl', 'wb') as f:\n",
    "            pickle.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:GASpy_conda]",
   "language": "python",
   "name": "conda-env-GASpy_conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "regress.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
